{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we had image size `(betch size, imange number, width, height) --> (64, 1, 28, 28)`\n",
    "- we are passing input as 28 (input_size) , one row at a time\n",
    "\n",
    "- sequence length is 28 mean, number of sequences feeded to model at time is 28 rows in one go\n",
    "\n",
    "- number of layers would be 2\n",
    "\n",
    "- hidden layer size is 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we ussually don't use RNNs for image data, for implementation purpose only we rae using it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)# initalizing hidden state 1st\n",
    "\n",
    "        # Forward pass\n",
    "        out, _ = self.rnn(x, h0) # '_' has hidden state as output / every point has its own hidden state\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when we write `batch_first = True` then input is `(batch_size, time_seq, features)`\n",
    "\n",
    "- in Lienar layer we are passing `hidden_size x sequence_length` we have `28` time sequences it will concatinate all those and thats what we are going to send to linear layer, so its going to use all information from all the hiddel sattes\n",
    "\n",
    "**Alternative option:**\n",
    "\n",
    "    - you can also take information from last hidden state\n",
    "\n",
    "- `out, _ = self.rnn(x, h0)` here `_` has hidden state output, every data point has its own hidden state\n",
    "\n",
    "- `out = out.reshape(out.shape[0], -1)` keeping `out.shape[0]` as batch size, changes rest `-1` = `(1 x 28 x 28)` = `784`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GRU Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)# initalizing hidden state 1st\n",
    "\n",
    "        # Forward pass\n",
    "        out, _ = self.gru(x, h0) # '_' has hidden state as output / every point has its own hidden state\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to use `GRU` we just have to change `RNN` unit with `GRU` they have same input and output, is just that internal structure changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)# initalizing hidden state 1st\n",
    "        \n",
    "        # cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # Forward pass\n",
    "        out, _ = self.lstm(x, (h0, c0)) # '_' has hidden state as output / every point has its own hidden state\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here in `LSTM`, it has two states to maintain, `cell state` for leng term context amd `hidden state` for short term context\n",
    "\n",
    "- we need to add once cell state in LSTM and add it in lstm layer as tuple\n",
    "\n",
    "- we don't have to perform concatination of all the state like `RNN` and `GRU`\n",
    "\n",
    "- we just take the last one in fully connected layer `out[:, -1, :]` -->  `[all training samples at same time , last hidden state,  all features]`, by doing this we are going to loose information , if some cases its better to take only relevaent infromation and training on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=False)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, )\n",
    "\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with RNN\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# model with GRU\n",
    "model1 = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# model with LSTM\n",
    "model2 = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Average Loss: 1.9105836407207986\n",
      "Epoch 1: Average Loss: 1.3656939141023388\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device).squeeze(1)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        scores = model2(data)\n",
    "\n",
    "        loss = criterion(scores, target)\n",
    "\n",
    "        # backward\n",
    "\n",
    "        model.zero_grad() # clear previous gradients\n",
    "\n",
    "        loss.backward() # back propogation\n",
    "\n",
    "        optimizer.step() # update mode weights\n",
    "\n",
    "        total_loss += loss.item() # Accumulate loss\n",
    "\n",
    "    average_loss = total_loss / len(train_loader) # Calculating average loss\n",
    "\n",
    "    print(f\"Epoch {epoch}: Average Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy on train & test see how good our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on testing data\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # put model into evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "\n",
    "            x = x.to(device).squeeze(1)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores =model(x)\n",
    "\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        acc = float(num_correct) / float(num_samples) * 100\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {acc:.2f}\")\n",
    "    \n",
    "    model.train() # putting model in training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Score Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 58274 / 60000 with accuracy 97.12\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on testing data\n",
      "Got 9717 / 10000 with accuracy 97.17\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUR Score Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 45052 / 60000 with accuracy 75.09\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on testing data\n",
      "Got 7585 / 10000 with accuracy 75.85\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Score Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 32751 / 60000 with accuracy 54.58\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on testing data\n",
      "Got 5424 / 10000 with accuracy 54.24\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
