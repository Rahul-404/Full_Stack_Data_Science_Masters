{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ridge Regression** $\\longrightarrow$ {L2 Regularization} $\\longrightarrow$ {Reduce Overfitting}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also say: low bias (low training error), high variance (hight test error)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/overfitting_[ridge_regression].png\" alt=\"overfitting\" width=\"400\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Training Error : $\\downarrow \\downarrow$ $\\longrightarrow$ Accuracy : $\\longrightarrow$ $R^2$ is very very $\\uparrow \\uparrow$\n",
    "\n",
    "Now, what happens with test error \n",
    "\n",
    "Test Error :  $\\uparrow \\uparrow$ $\\longrightarrow$ Accuracy : $\\longrightarrow$ $R^2$ is very very $\\downarrow \\downarrow$\n",
    "\n",
    "we can call this scenario as **Overfitting** , means for training model has by hearted everything, but for the test data (test paper) it has failed badly,\n",
    "\n",
    "now **Question** arises, \n",
    "\n",
    "**Q.** how do we solve this problem ?\n",
    " \n",
    "$\\longrightarrow$ When ever i have my training data i am always going to make sure that i don't perfectly fit, that is what we need to do. (there should be some error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What should be my main aim here ?\n",
    "\n",
    "$\\longrightarrow$ My main aim should be that, i should fit a line to training data such a way that there definitely should be some error. if i am getting erro 0 (zero) mean i am overfitting it , which will lead to overfitting scenario for test data \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/overfitting_solution_[ridge_regression].png\" alt=\"overfitting\" width=\"400\" height=\"300\">\n",
    "</p>\n",
    "\n",
    ", so what i will do, will try to create some best fit line which will be of different from existing model's best fit line, and it will also perform best that exisiting ones. both newly drawn lines will do the best as compare to given fitted model, but with new lines will get some training error, so there will be some test error also but it will never be zero, the train data will not fail , it's like your are reading for your exam and leavning some questions and reading some questions from out-side the book, but luckily or unluciky it comes near by to that question, we will be able to answer it.\n",
    "\n",
    "What is amazing about this ridge equation is that , obviously the cost function is same. cost function can be $MAE$, $MSE$ or $RMSE$. \n",
    "\n",
    "means in general terms,\n",
    "\n",
    "$Cost$ $Function = MAE/MSE/RMSE + \\lambda * \\sum_{i=1}^{n} (slope)^2$\n",
    "\n",
    "\n",
    "in our case it is,\n",
    "\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + \\lambda * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "here, \n",
    "- $Slope = \\theta_1$, but in case of multiple regression it will be $\\theta_1, \\theta_2, \\theta_3, ...., \\theta_n$\n",
    "\n",
    "\n",
    "$ \\lambda * \\sum_{i=1}^{n} (slope)^2 $, this is panelty or can say our $L2$ regularization.\n",
    "\n",
    "Let's go and define each and every parameter,\n",
    "\n",
    "- $\\lambda$ is kind of a hyperparameter we can use different-different values, basically define how much error we want w.r.t to training data.\n",
    "- $(Slope)^2$ is nothing but co-efficient square  \n",
    "\n",
    "but there is one very important thing which we will be going see now,\n",
    "\n",
    "that is relation between $\\lambda$ and $Slope$, can we say $Slope$ is nothing but $\\theta$\n",
    "\n",
    "Now, if we plot $\\theta$ with $J(\\theta)$\n",
    "\n",
    "Consider diffrent cases of $\\lambda$\n",
    "\n",
    "**CASE 1 :** $\\lambda = 0$ put it in the cost function\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + \\lambda * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + 0 * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 $ $\\longrightarrow$ nothing but $MSE$\n",
    "\n",
    "in this case we are going to get just a normal parabola curve, and at bottom will have our **global minima**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "Now let's go a head and increase our $\\lambda$ value to $10$\n",
    "\n",
    "we will be seeing some new characterstics w.r.t to curve which will now become something like you see in below image\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot1.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "**Q.** What has happened basically in above image ?\n",
    "\n",
    "$\\longrightarrow$ our **global minima** has moved above\n",
    "\n",
    "Now let's go a head and increase our $\\lambda$ value to $20$\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot2.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "**Q.** What has happened basically in above image ?\n",
    "\n",
    "$\\longrightarrow$ again, our **global minima** is moving, basicallu shiftting.\n",
    "\n",
    "- When our **global minima** is shiftting, $\\theta$ is shifting, but it will never become zero.\n",
    "\n",
    "Now tell me **what will happen if $\\theta$ get zero then ?** (think over here, think)\n",
    "\n",
    "$\\longrightarrow$ that feature will get removed, whoes coefficient is became zero, and we don't want that, but based on that $\\theta$ value we are adding some error, we are penalizing the cost function with some error by multipling $\\lambda$ with $\\sum(slope)^2$. because of this my line will not be perfectly fitted. Definitely there will be some error or can say some gap.\n",
    "\n",
    "Which ever will be some minimalistic gap that will peobabily take care of. Now this should make sense. by end of this you should understand the relationship between $\\lambda$ and $\\theta$, this what you really need to remember. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say my $h_\\theta(n) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3$ this is a multiple linear regression.\n",
    "\n",
    "**Q.** How many independent features we have ?\n",
    "\n",
    "$\\longrightarrow$ we have [$x_1, x_2, x_3$] \n",
    "\n",
    "**Q.** how many co-efficient i have ?\n",
    "\n",
    "$\\longrightarrow$ we have [$\\theta_1, \\theta_2, \\theta_3$] \n",
    "\n",
    "So, what will be my cost function for this equation ?\n",
    "\n",
    "$\\longrightarrow$ $Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} (y _i - \\hat{y_i})^2 + \\lambda * [ ( \\theta_1 )^2 + ( \\theta_2 )^2 + ( \\theta_3 )^2 ]$\n",
    "\n",
    "\n",
    "**Q&A**\n",
    "\n",
    "- can weights become zero after L2 regularization ?\n",
    "\n",
    "$\\longrightarrow$ No, it will never become zero, it will only get near to zero but it will never get zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lasso Regression** $\\longrightarrow$ {L1 Regularization} $\\longrightarrow$ {Feature Selection}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ElasticNet Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
