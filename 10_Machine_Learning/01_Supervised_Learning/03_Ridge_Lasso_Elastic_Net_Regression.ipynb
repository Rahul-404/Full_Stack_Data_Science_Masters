{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ridge Regression** $\\longrightarrow$ {L2 Regularization} $\\longrightarrow$ {Reduce Overfitting}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also say: low bias (low training error), high variance (hight test error)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/overfitting_[ridge_regression].png\" alt=\"overfitting\" width=\"400\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Training Error : $\\downarrow \\downarrow$ $\\longrightarrow$ Accuracy : $\\longrightarrow$ $R^2$ is very very $\\uparrow \\uparrow$\n",
    "\n",
    "Now, what happens with test error \n",
    "\n",
    "Test Error :  $\\uparrow \\uparrow$ $\\longrightarrow$ Accuracy : $\\longrightarrow$ $R^2$ is very very $\\downarrow \\downarrow$\n",
    "\n",
    "we can call this scenario as **Overfitting** , means for training model has by hearted everything, but for the test data (test paper) it has failed badly,\n",
    "\n",
    "now **Question** arises, \n",
    "\n",
    "**Q.** how do we solve this problem ?\n",
    " \n",
    "$\\longrightarrow$ When ever i have my training data i am always going to make sure that i don't perfectly fit, that is what we need to do. (there should be some error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What should be my main aim here ?\n",
    "\n",
    "$\\longrightarrow$ My main aim should be that, i should fit a line to training data such a way that there definitely should be some error. if i am getting erro 0 (zero) mean i am overfitting it , which will lead to overfitting scenario for test data \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/overfitting_solution_[ridge_regression].png\" alt=\"overfitting\" width=\"400\" height=\"300\">\n",
    "</p>\n",
    "\n",
    ", so what i will do, will try to create some best fit line which will be of different from existing model's best fit line, and it will also perform best that exisiting ones. both newly drawn lines will do the best as compare to given fitted model, but with new lines will get some training error, so there will be some test error also but it will never be zero, the train data will not fail , it's like your are reading for your exam and leavning some questions and reading some questions from out-side the book, but luckily or unluciky it comes near by to that question, we will be able to answer it.\n",
    "\n",
    "What is amazing about this ridge equation is that , obviously the cost function is same. cost function can be $MAE$, $MSE$ or $RMSE$. \n",
    "\n",
    "means in general terms,\n",
    "\n",
    "$Cost$ $Function = MAE/MSE/RMSE + \\lambda * \\sum_{i=1}^{n} (slope)^2$\n",
    "\n",
    "\n",
    "in our case it is,\n",
    "\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + \\lambda * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "here, \n",
    "- $Slope = \\theta_1$, but in case of multiple regression it will be $\\theta_1, \\theta_2, \\theta_3, ...., \\theta_n$\n",
    "\n",
    "\n",
    "$ \\lambda * \\sum_{i=1}^{n} (slope)^2 $, this is panelty or can say our $L2$ regularization.\n",
    "\n",
    "Let's go and define each and every parameter,\n",
    "\n",
    "- $\\lambda$ is kind of a hyperparameter we can use different-different values, basically define how much error we want w.r.t to training data.\n",
    "- $(Slope)^2$ is nothing but co-efficient square  \n",
    "\n",
    "but there is one very important thing which we will be going see now,\n",
    "\n",
    "that is relation between $\\lambda$ and $Slope$, can we say $Slope$ is nothing but $\\theta$\n",
    "\n",
    "Now, if we plot $\\theta$ with $J(\\theta)$\n",
    "\n",
    "Consider diffrent cases of $\\lambda$\n",
    "\n",
    "**CASE 1 :** $\\lambda = 0$ put it in the cost function\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + \\lambda * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 + 0 * \\sum_{i=1}^{n} (slope)^2 $\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y_i} )^2 $ $\\longrightarrow$ nothing but $MSE$\n",
    "\n",
    "in this case we are going to get just a normal parabola curve, and at bottom will have our **global minima**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "Now let's go a head and increase our $\\lambda$ value to $10$\n",
    "\n",
    "we will be seeing some new characterstics w.r.t to curve which will now become something like you see in below image\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot1.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "**Q.** What has happened basically in above image ?\n",
    "\n",
    "$\\longrightarrow$ our **global minima** has moved above\n",
    "\n",
    "Now let's go a head and increase our $\\lambda$ value to $20$\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/[ridge_regression]_cost_function_plot2.png\" alt=\"lambda=0\" width=\"500\" height=\"300\">\n",
    "</p>\n",
    "\n",
    "**Q.** What has happened basically in above image ?\n",
    "\n",
    "$\\longrightarrow$ again, our **global minima** is moving, basicallu shiftting.\n",
    "\n",
    "- When our **global minima** is shiftting, $\\theta$ is shifting, but it will never become zero.\n",
    "\n",
    "Now tell me **what will happen if $\\theta$ get zero then ?** (think over here, think)\n",
    "\n",
    "$\\longrightarrow$ that feature will get removed, whoes coefficient is became zero, and we don't want that, but based on that $\\theta$ value we are adding some error, we are penalizing the cost function with some error by multipling $\\lambda$ with $\\sum(slope)^2$. because of this my line will not be perfectly fitted. Definitely there will be some error or can say some gap.\n",
    "\n",
    "Which ever will be some minimalistic gap that will peobabily take care of. Now this should make sense. by end of this you should understand the relationship between $\\lambda$ and $\\theta$, this what you really need to remember. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say my $h_\\theta(n) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3$ this is a multiple linear regression.\n",
    "\n",
    "**Q.** How many independent features we have ?\n",
    "\n",
    "$\\longrightarrow$ we have [$x_1, x_2, x_3$] \n",
    "\n",
    "**Q.** how many co-efficient i have ?\n",
    "\n",
    "$\\longrightarrow$ we have [$\\theta_1, \\theta_2, \\theta_3$] \n",
    "\n",
    "So, what will be my cost function for this equation ?\n",
    "\n",
    "$\\longrightarrow$ $Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} (y _i - \\hat{y_i})^2 + \\lambda * [ ( \\theta_1 )^2 + ( \\theta_2 )^2 + ( \\theta_3 )^2 ]$\n",
    "\n",
    "\n",
    "**Q&A**\n",
    "\n",
    "- can weights become zero after L2 regularization ?\n",
    "\n",
    "$\\longrightarrow$ No, it will never become zero, it will only get near to zero but it will never get zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lasso Regression** $\\longrightarrow$ {L1 Regularization} $\\longrightarrow$ {Feature Selection}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define cost function for it\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 + \\lambda * \\sum_{i=1}^{n} |Slope|$\n",
    "\n",
    "before it was square now it is mod. and this equation is used for **feature selection**\n",
    "\n",
    "Let's say i have some equation of \n",
    "\n",
    "$h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3$\n",
    "\n",
    "and let's say i have some values here with it\n",
    "\n",
    "$h_\\theta(x) = 0.52 + 0.65 * x_1  + 1.5 *  x_2 + 0.2 * x_3$\n",
    "\n",
    "Don't you think so the coefficient of $x_3$ is just very less as comapred to other co-efficients, and based on this i can remove this feature from features list because this may not be that important, because there is very minimalistic moment w.r.t $x_3$ or can say $x_3$ is contributing very less for making prediction, don't you think w.r.t features we should perform some feature selection and remove less important features because it is not contributing that much while predicting \n",
    "\n",
    "Now what does this mean ?\n",
    "\n",
    "- if $x_1$ is moving by $0.65$ unit then the output feature is moved by how much unit, or $1$ unit moment in $y$ is causing $0.65$ unit moment in $x_1$.\n",
    "\n",
    "Similally,\n",
    "\n",
    "- $1$ unit moment in y is causing $1.5$ unit moment in $x_2$\n",
    "\n",
    "- $1$ unit moment in y is causing $0.2$ unit moment in $x_3$ (out of all this is not that important)\n",
    "\n",
    "if $x_3$ is not that important, we can remove it from our feature list, if we keep it, it will just overfit the model at the end of day.\n",
    "\n",
    "\n",
    "$Cost$ $Function = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 + \\lambda * \\sum_{i=1}^{n} |Slope|$\n",
    "\n",
    "for above cost function also as we keep increasing  the value of $\\lambda$ from zero to $+ \\infty$, we will be observing a trait init \n",
    "- that at every time $\\lambda$ increase the parabola is keep on going up and up and up, after some point of time it will completly lying in zero, basically it will stop at zero, don't you think so that specific $\\theta$ values is minimized. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[image of lasso cost function]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ElasticNet Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
